{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process as pc\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage import img_as_float\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.image as mpimg\n",
    "import joblib\n",
    "import cv2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already extracted\n"
     ]
    }
   ],
   "source": [
    "positive_images_path = pc.DATA_PATH+\"/img_align_celeba\"\n",
    "negative_images_path = pc.DATA_PATH+\"/caltech-101/101_ObjectCategories\"\n",
    "\n",
    "pc.extract_dataset(positive_images_path)\n",
    "bad_imgs_path_list = pc.extract_dataset(negative_images_path, folder=\"multi_folders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrmic/ml_fondamenti_project/face_detection_project_2/src/user_warnings.py:4: UserWarning: The requested number of images is greater than the number of images in the folder\n",
      "  warnings.warn(\"The requested number of images is greater than the number of images in the folder\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8275"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_good_images = 20000\n",
    "n_bad_images_folder=1000\n",
    "size_w = size_h = 128\n",
    "\n",
    "#count bad images:\n",
    "bad_img_list = []\n",
    "for fld in bad_imgs_path_list:\n",
    "    tmp_img_list = pc.load_images(negative_images_path+\"/\"+fld, number_of_images=n_bad_images_folder, random_seed=7)\n",
    "    bad_img_list += [negative_images_path+\"/\"+fld+'/'+img for img in tmp_img_list]\n",
    "\n",
    "len(bad_img_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26413"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract patch from bad images to increase the number of negative samples\n",
    "bad_patches = pc.extract_patches(bad_img_list, (size_w, size_h), n_patches=25000, random_seed=7)\n",
    "len(bad_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = pc.load_images(positive_images_path, number_of_images=n_good_images, random_seed=7) \n",
    "images = np.empty((n_good_images, size_w, size_h), dtype=np.uint8)\n",
    "\n",
    "for i, img in enumerate(img_list):\n",
    "    image = cv2.imread(pc.DATA_PATH+\"/img_align_celeba/\"+img)\n",
    "    images[i, ...] = pc.process_image(image, resize=True, img_resize=(size_w, size_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /io/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m bad_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mlen\u001b[39m(bad_patches), size_w, size_h), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bad_patches)), bad_patches):\n\u001b[0;32m----> 4\u001b[0m     bad_images[i, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_resize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_h\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ml_fondamenti_project/face_detection_project_2/src/process.py:100\u001b[0m, in \u001b[0;36mprocess_image\u001b[0;34m(image, resize, img_resize, diff_of_gaussian)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_image\u001b[39m(image, resize:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, img_resize:\u001b[38;5;28mtuple\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m), diff_of_gaussian:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 100\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resize:\n\u001b[1;32m    102\u001b[0m         img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, img_resize)\n",
      "File \u001b[0;32m~/ml_fondamenti_project/face_detection_project_2/src/process.py:91\u001b[0m, in \u001b[0;36mdenoise_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoise_image\u001b[39m(image):\n\u001b[1;32m     90\u001b[0m     image \u001b[38;5;241m=\u001b[39m img_as_float(image)\n\u001b[0;32m---> 91\u001b[0m     denoised_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGaussianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised_image\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /io/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n"
     ]
    }
   ],
   "source": [
    "bad_images = np.empty((len(bad_patches), size_w, size_h), dtype=np.uint8)\n",
    "\n",
    "for i, img in zip(range(len(bad_patches)), bad_patches):\n",
    "    bad_images[i, ...] = pc.process_image(img, resize=True, img_resize=(size_w, size_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax[i, j].imshow(images[i*10+j], cmap='gray')\n",
    "        ax[i, j].axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        ax[i, j].imshow(bad_images[i*10+j], cmap='gray')\n",
    "        ax[i, j].axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape\n",
    "bad_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.concatenate((images, bad_images), axis=0)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extractor = \"SIFT\"\n",
    "good_samples = n_good_images\n",
    "bad_samples = bad_images.shape[0]\n",
    "n_keypoints = 40\n",
    "n_features = 128#256\n",
    "if features_extractor == \"ORB\":\n",
    "   ftr_shape = n_keypoints*n_features\n",
    "   init = False\n",
    "   for i, img in enumerate(dataset):\n",
    "      _, features = pc.extract_ORB_features(img, n_keypoints=32)\n",
    "      if features is None:\n",
    "         if i < good_samples:\n",
    "               good_samples -= 1\n",
    "         else:\n",
    "            bad_samples -= 1\n",
    "         continue\n",
    "      features = features.flatten()\n",
    "      if features.shape[0] == ftr_shape:\n",
    "         if not init:\n",
    "            X = np.array([features])\n",
    "            init = True\n",
    "         else:\n",
    "            X = np.append(X, [features], axis=0)\n",
    "      else:\n",
    "         if i < good_samples:\n",
    "            print(\"good sample\")\n",
    "            good_samples -= 1\n",
    "         else:\n",
    "            print(\"bad sample\")\n",
    "            bad_samples -= 1\n",
    "\n",
    "\n",
    "if features_extractor == \"SIFT\":\n",
    "   ftr_shape = n_keypoints*n_features\n",
    "   init = False\n",
    "   for i, img in enumerate(dataset):\n",
    "      kp, features = pc.extract_SIFT_features(img, n_optimal_keypoints=n_keypoints)\n",
    "      if len(kp) < n_keypoints:\n",
    "         if i < good_samples:\n",
    "               good_samples -= 1\n",
    "         else:\n",
    "            bad_samples -= 1\n",
    "         continue\n",
    "\n",
    "      features = features.flatten()\n",
    "      if features.shape[0] == ftr_shape:\n",
    "         if not init:\n",
    "            X = np.array([features])\n",
    "            init = True\n",
    "         else:\n",
    "            X = np.append(X, [features], axis=0)\n",
    "      else:\n",
    "         if i < good_samples:\n",
    "            print(\"good sample\")\n",
    "            good_samples -= 1\n",
    "         else:\n",
    "            print(\"bad sample\")\n",
    "            bad_samples -= 1\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape[0] == ftr_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_samples\n",
    "bad_samples\n",
    "y = np.concatenate((np.ones(good_samples), np.zeros(bad_samples))) \n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "y_train.shape\n",
    "\n",
    "X_train[0]\n",
    "y_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=32, whiten=True, random_state=7)\n",
    "pca.fit(X_train)\n",
    "var = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(var)\n",
    "plt.ylim(0, 1.02)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance')\n",
    "plt.show()\n",
    "var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [i for i in range(len(var)) if var[i] > 0.95]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    pca = PCA(n_components=idx[-1], whiten=True, random_state=7)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    X_train_pca.shape\n",
    "    y_train.shape\n",
    "    print(\"PCA done\")\n",
    "else:\n",
    "    X_train_pca = X_train\n",
    "    X_test_pca = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_pca)\n",
    "X_test_scaled = scaler.transform(X_test_pca)\n",
    "X_train_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { 'C' : [np.power(10., i) for i in range(-2, 2)],\n",
    "               'max_iter' : [7500],\n",
    "               'random_state' : [7] }\n",
    "\n",
    "grid_searh = GridSearchCV(LinearSVC(), param_grid, cv=5, n_jobs=2)\n",
    "grid_searh.fit(X_train_pca, y_train)\n",
    "grid_searh.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc = grid_searh.best_estimator_\n",
    "\n",
    "best_svc.score(X_train_pca, y_train)\n",
    "\n",
    "best_svc.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_svc.predict(X_train_pca)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(\"Accuracy test:\", accuracy)\n",
    "\n",
    "\n",
    "y_pred = best_svc.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy test:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_save_path = pc.DATA_PATH+\"/sift_features.pkl\"\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocess', pc.process_image),\n",
    "        ('extract_features', pc.extract_ORB_features),\n",
    "        ('pca', pca),\n",
    "        ('svc', best_svc)  \n",
    "    ])\n",
    "\n",
    "joblib.dump(\n",
    "    pipeline, pipeline_save_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_save_path = pc.DATA_PATH+\"/sift_features.pkl\"\n",
    "image_path = pc.DATA_PATH+\"/final/Valentino_Rossi_2017.jpg\"\n",
    "\n",
    "pipeline = joblib.load(pipeline_save_path)\n",
    "\n",
    "image = mpimg.imread(image_path)\n",
    "\n",
    "faces = pc.detect_faces(image, pipeline, threshold=0.5, window_size=(128, 128), step_size=(64, 64), n_keypoints=32, resize=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
